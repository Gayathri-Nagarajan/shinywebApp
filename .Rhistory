install.packages("AppliedPredictiveModeling")
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
dim(training)
dim(testing)
#131 predictors
set.seed(62433)
RFfit <- train(diagnosis~ .,data=training,method="rf")
RFpred <- predict(RFfit,testing)
confusionMatrix(RFpred,testing$diagnosis)$overall['Accuracy']
Bofit <- train(y~ .,data=training,method="gbm",verbose=FALSE)
Bopred <- predict(Bofit,testing)
confusionMatrix(Bopred,testing$diagnosis)$overall['Accuracy']
confusionMatrix(RFpred,testing$diagnosis)
confusionMatrix(Bopred,testing$diagnosis)
Bopred <- predict(Bofit,testing)
#0.9024
Bofit <- train(y~ .,data=training,method="gbm",verbose=FALSE)
#0.9024
Bofit <- train(diagnosis~ .,data=training,method="gbm",verbose=FALSE)
Bopred <- predict(Bofit,testing)
confusionMatrix(Bopred,testing$diagnosis)
#0.8902
#lda
ldafit <- train(diagnosis~ .,data=training,method="lda",verbose=FALSE)
ldapred <- predict(ldafit,testing)
confusionMatrix(ldapred,testing$diagnosis)
#Stack all three predictions
predDF <- data.frame(RFpred,bopred,ldapred,diagnosis=testing$diagnosis)
#Stack all three predictions
predDF <- data.frame(RFpred,Bopred,ldapred,diagnosis=testing$diagnosis)
OverallFit <- train( diagnosis ~.,data=predDF,method="gam")
OverallFit
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
knitr::opts_chunk$set(include = FALSE)
library(Boruta)
library(caret)
library(mlbench)
library(randomForest)
library(dplyr)
library(dplyr)
set.seed(111)
setwd( "C:\\Users\\RamamurthyV\\Documents\\R\\8.Machine Learning\\Project ML")
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
#str(training)
dim(training)
#19622, 160 col
dim(testing)
#str(testing)
#20, 160 col
#https://www.youtube.com/watch?v=dJclNIN-TPo&t=501s check this for random forest with Bagging
#Check model ensembling in practical machine learning course notes
#remove any columnn that has NA
#select only columns that dont have even one NA value
t1 <- training %>%
select_if(~ !any(is.na(.)))
#dim(t1)
#Only 93 have non NA
#Identify and remove near zero variance predictors
nzv <- nearZeroVar(t1)
nzv
#length(nzv)
#34
newTraining <- t1[, -nzv]
#19622 rows with 93-34=59 columns after removing the columns that had even 1 NA
dim(newTraining)
#19622 59
#str(newTraining)
#Use cross validation to partition training set into 10 folds
newdata_train <-createDataPartition(newTraining$classe,p=0.7,list=FALSE)
newdata_train
trg <- newTraining[newdata_train,]
tst <- newTraining[-newdata_train,]
dim(trg)
#13737 59
dim(tst)
#5885 59
#trg
#remove the classe independent variable which we want to predict
col_names_trg <- names(trg[,-59])
#col_names_trg
#class(col_names_trg)
#length(col_names_trg)
#58 columns only
#Pick only these from the training original set
testing <- data.frame(testing)
dim(testing)
#class(testing)
#tail(testing)
#col_names_trg
final_t<- select(testing,all_of(col_names_trg))
#final_t
#Using cross validation in the trng set
splitrule <- trainControl(method="repeatedcv",repeats=3,number=2,classProbs = TRUE)
splitrule
gbmModel <- train(classe~.,data=trg,trControl=splitrule,method="gbm",preProc=c("center","scale"),metric="ROC")
#Took time 4:58 pm to
summary(gbmModel)
gbmTest<- predict(gbmModel, newdata = tst)
#length(gbmTest)
confusionMatrix(gbmTest,tst$classe)
#Accuracy is 0.9998
#calculate rmse
#sqrt(mean(gbmTest-tst$classe)^2)
table(tst$classe) #actuals numbers in each category of classe
#RF model
rfModel <- train(classe~.,data=trg,trControl=splitrule,method="rf",preProc=c("center","scale"),metric="ROC")
summary(rfModel)
rfTest<- predict(rfModel, newdata = tst)
confusionMatrix(rfTest,tst$classe)
#Accuracy is 1
#Random Forest
randomf <- randomForest(classe ~.,data=trg)
print(randomf)
#No errors
attributes(randomf)
randomf$confusion
randomp<- predict(randomf, newdata=tst)
#NO errors
#head(randomp)
#head(tst$classe)
confusionMatrix(randomp,tst$classe)
#Accuracy is 1
#Plot our model for showing Out of Bag Error
plot(randomf)
#Check the final_testing model for prediction
gbmfinal<- predict(gbmModel, newdata = final_t)
gbmfinal
#All are A's
#Check the final_testing model for prediction using rf
#We have predicted all 20 to be in class A
rffinal<- predict(rfModel, newdata = final_t)
rffinal
#All A's
plot(rffinal)
plot(gbmfinal)
plot(gbmModel)
plot(randomf)
plot(rffinal)
plot(gbmfinal)
plot(gbmModel)
plot(gbmfinal)
plot(randomf)
plot(rffinal)
knitr::opts_chunk$set(include = FALSE)
library(Boruta)
library(caret)
library(mlbench)
library(randomForest)
library(dplyr)
library(dplyr)
set.seed(111)
setwd( "C:\\Users\\RamamurthyV\\Documents\\R\\8.Machine Learning\\Project ML")
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
#str(training)
dim(training)
#19622, 160 col
dim(testing)
#str(testing)
#20, 160 col
#https://www.youtube.com/watch?v=dJclNIN-TPo&t=501s check this for random forest with Bagging
#Check model ensembling in practical machine learning course notes
#remove any columnn that has NA
#select only columns that dont have even one NA value
t1 <- training %>%
select_if(~ !any(is.na(.)))
#dim(t1)
#Only 93 have non NA
#Identify and remove near zero variance predictors
nzv <- nearZeroVar(t1)
nzv
#length(nzv)
#34
newTraining <- t1[, -nzv]
#19622 rows with 93-34=59 columns after removing the columns that had even 1 NA
dim(newTraining)
#19622 59
#str(newTraining)
#Use cross validation to partition training set into 10 folds
newdata_train <-createDataPartition(newTraining$classe,p=0.7,list=FALSE)
newdata_train
trg <- newTraining[newdata_train,]
tst <- newTraining[-newdata_train,]
dim(trg)
#13737 59
dim(tst)
#5885 59
#trg
#remove the classe independent variable which we want to predict
col_names_trg <- names(trg[,-59])
#col_names_trg
#class(col_names_trg)
#length(col_names_trg)
#58 columns only
#Pick only these from the training original set
testing <- data.frame(testing)
dim(testing)
#class(testing)
#tail(testing)
#col_names_trg
final_t<- select(testing,all_of(col_names_trg))
#final_t
#Using cross validation in the trng set
splitrule <- trainControl(method="repeatedcv",repeats=3,number=2,classProbs = TRUE)
splitrule
gbmModel <- train(classe~.,data=trg,trControl=splitrule,method="gbm",preProc=c("center","scale"),metric="ROC")
#Took time 4:58 pm to
summary(gbmModel)
gbmTest<- predict(gbmModel, newdata = tst)
#length(gbmTest)
confusionMatrix(gbmTest,tst$classe)
#Accuracy is 0.9998
#calculate rmse
#sqrt(mean(gbmTest-tst$classe)^2)
table(tst$classe) #actuals numbers in each category of classe
#RF model
rfModel <- train(classe~.,data=trg,trControl=splitrule,method="rf",preProc=c("center","scale"),metric="ROC")
summary(rfModel)
rfTest<- predict(rfModel, newdata = tst)
confusionMatrix(rfTest,tst$classe)
#Accuracy is 1
#Random Forest
randomf <- randomForest(classe ~.,data=trg)
print(randomf)
#No errors
attributes(randomf)
randomf$confusion
randomp<- predict(randomf, newdata=tst)
#NO errors
#head(randomp)
#head(tst$classe)
confusionMatrix(randomp,tst$classe)
#Accuracy is 1
#Plot our model for showing Out of Bag Error
plot(randomf)
#Check the final_testing model for prediction
gbmfinal<- predict(gbmModel, newdata = final_t)
gbmfinal
#All are A's
#Check the final_testing model for prediction using rf
#We have predicted all 20 to be in class A
rffinal<- predict(rfModel, newdata = final_t)
rffinal
#All A's
plot(gbmModel)
plot(gbmfinal)
plot(randomf)
plot(rffinal)
knitr::opts_chunk$set(include = FALSE)
library(Boruta)
library(caret)
library(mlbench)
library(randomForest)
library(dplyr)
library(dplyr)
set.seed(111)
setwd( "C:\\Users\\RamamurthyV\\Documents\\R\\8.Machine Learning\\Project ML")
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
#str(training)
dim(training)
#19622, 160 col
dim(testing)
#str(testing)
#20, 160 col
#https://www.youtube.com/watch?v=dJclNIN-TPo&t=501s check this for random forest with Bagging
#Check model ensembling in practical machine learning course notes
#remove any columnn that has NA
#select only columns that dont have even one NA value
t1 <- training %>%
select_if(~ !any(is.na(.)))
#dim(t1)
#Only 93 have non NA
#Identify and remove near zero variance predictors
nzv <- nearZeroVar(t1)
nzv
#length(nzv)
#34
newTraining <- t1[, -nzv]
#19622 rows with 93-34=59 columns after removing the columns that had even 1 NA
dim(newTraining)
#19622 59
#str(newTraining)
#Use cross validation to partition training set into 10 folds
newdata_train <-createDataPartition(newTraining$classe,p=0.7,list=FALSE)
newdata_train
trg <- newTraining[newdata_train,]
tst <- newTraining[-newdata_train,]
dim(trg)
#13737 59
dim(tst)
#5885 59
#trg
#remove the classe independent variable which we want to predict
col_names_trg <- names(trg[,-59])
#col_names_trg
#class(col_names_trg)
#length(col_names_trg)
#58 columns only
#Pick only these from the training original set
testing <- data.frame(testing)
dim(testing)
#class(testing)
#tail(testing)
#col_names_trg
final_t<- select(testing,all_of(col_names_trg))
#final_t
#Using cross validation in the trng set
splitrule <- trainControl(method="repeatedcv",repeats=3,number=2,classProbs = TRUE)
splitrule
gbmModel <- train(classe~.,data=trg,trControl=splitrule,method="gbm",preProc=c("center","scale"),metric="ROC")
#Took time 4:58 pm to
summary(gbmModel)
gbmTest<- predict(gbmModel, newdata = tst)
#length(gbmTest)
confusionMatrix(gbmTest,tst$classe)
#Accuracy is 0.9998
#calculate rmse
#sqrt(mean(gbmTest-tst$classe)^2)
table(tst$classe) #actuals numbers in each category of classe
#RF model
rfModel <- train(classe~.,data=trg,trControl=splitrule,method="rf",preProc=c("center","scale"),metric="ROC")
summary(rfModel)
rfTest<- predict(rfModel, newdata = tst)
confusionMatrix(rfTest,tst$classe)
#Accuracy is 1
#Random Forest
randomf <- randomForest(classe ~.,data=trg)
print(randomf)
#No errors
attributes(randomf)
randomf$confusion
randomp<- predict(randomf, newdata=tst)
#NO errors
#head(randomp)
#head(tst$classe)
confusionMatrix(randomp,tst$classe)
#Accuracy is 1
#Plot our model for showing Out of Bag Error
plot(randomf)
#Check the final_testing model for prediction
gbmfinal<- predict(gbmModel, newdata = final_t)
gbmfinal
#All are A's
#Check the final_testing model for prediction using rf
#We have predicted all 20 to be in class A
rffinal<- predict(rfModel, newdata = final_t)
rffinal
#All A's
plot(gbmModel)
plot(gbmfinal)
plot(randomf)
plot(rffinal)
install.packages("googleVis")
library(googleVis)
G <- gvisGeoChart(Exports, locationvar="Country",
colorvar="Profit",options=list(width=600, height=400))
print(G,"chart")
G <- gvisGeoChart(Exports, locationvar="Country",
colorvar="Profit",options=list(width=600, height=400))
print(G,"chart")
G
M <- gvisMotionChart(Fruits, "Fruit", "Year",
options=list(width=600, height=400))
print(M,"chart")
plot(M)
plot(G)
install.packages("plotly")
knitr::opts_chunk$set(echo = TRUE)
library(plotly)
data(mtcars)
plot_Ly(mtcars, x=wt, y=mpg, mode="markers")
library(plotly)
data(mtcars)
plot_ly(mtcars, x=wt, y=mpg, mode="markers")
library(plotly)
data(mtcars)
plot_ly(mtcars, x=wt, y=mpg, mode="markers")
plot_ly(mtcars, x=wt, y=mpg, mode="markers")
data(mtcars)
head(mtcars)
plot_ly(mtcars, x=wt, y=mpg, mode="markers")
plot_ly(mtcars, x = wt, y=mpg, mode="markers")
?plot_ly
plot_ly("mtcars"", x = wt, y=mpg, type="markers")
plot_ly("mtcars", x = wt, y=mpg, type="markers")
plot_ly(mtcars, x = wt, y=mpg, type="markers")
plot_ly(mtcars, x = tcars$wt, y=mpg, type="markers")
plot_ly(mtcars, x = mtcars$wt, y=mpg, type="markers")
plot_ly(mtcars, x = mtcars$wt, y=mpg, type="scatter")
plot_ly(mtcars, x = mtcars$wt, y=mpg, type="scatter")
dim(mmtcars
)
dim(mtcars)
plot_ly(mtcars, x = mtcars$wt, y=mpg, type="scatter",color=as.factor(mtcars$cyl))
plot_ly(mtcars, x = mtcars$wt, y=mpg, type="scatter",color=disp))
plot_ly(mtcars, x = mtcars$wt, y=mpg, type="scatter",color=as.factor(mtcars$cyl),size= mtcars$hp)
plot_ly(mtcars, x = mtcars$wt, y=mpg, z = mtcars$hp type="scatter3d",color=mtcars$wt)
plot_ly(mtcars, x = mtcars$wt, y=mpg, z = mtcars$hp type="scatter3d",color=mtcars$wt)
?plot_ly
library(plotly)
trace_0 <- rnorm(100, mean = 5)
trace_1 <- rnorm(100, mean = 0)
trace_2 <- rnorm(100, mean = -5)
x <- c(1:100)
data <- data.frame(x, trace_0, trace_1, trace_2)
fig <- plot_ly(data, x = ~x)
fig <- fig %>% add_trace(y = ~trace_0, name = 'trace 0',mode = 'lines')
fig <- fig %>% add_trace(y = ~trace_1, name = 'trace 1', mode = 'lines+markers')
fig <- fig %>% add_trace(y = ~trace_2, name = 'trace 2', mode = 'markers')
fig
library(plotly)
trace_0 <- rnorm(100, mean = 5)
trace_1 <- rnorm(100, mean = 0)
trace_2 <- rnorm(100, mean = -5)
x <- c(1:100)
data <- data.frame(x, trace_0, trace_1, trace_2)
fig <- plot_ly(data, x = ~x)
fig <- fig %>% add_trace(y = ~trace_0, name = 'trace 0',mode = 'lines')
data <- data.frame(x, trace_0, trace_1, trace_2)
data <- data.frame(x, trace_0, trace_1, trace_2)
fig <- plot_ly(data, x = ~x)
fig <- fig %>% add_trace(y = ~trace_0, name = 'trace 0',mode = 'lines')
fig <- fig %>% add_trace(y = ~trace_1, name = 'trace 1', mode = 'lines+markers')
fig <- fig %>% add_trace(y = ~trace_2, name = 'trace 2', mode = 'markers')
fig
library(plotly)
mtcars$am[which(mtcars$am == 0)] <- 'Automatic'
mtcars$am[which(mtcars$am == 1)] <- 'Manual'
mtcars$am <- as.factor(mtcars$am)
head(mtcars)
fig <- plot_ly(mtcars, x = ~wt, y = ~hp, z = ~qsec, color = ~am, colors = c('#BF382A', '#0C4B8E'))
fig <- fig %>% add_markers()
fig <- fig %>% layout(scene = list(xaxis = list(title = 'Weight'),
yaxis = list(title = 'Gross horsepower'),
zaxis = list(title = '1/4 mile time')))
fig
fig
library(plotly)
df <- read.csv("https://raw.githubusercontent.com/plotly/datasets/master/2014_world_gdp_with_codes.csv")
df
dim(df)
fig <- plot_ly(df, type='choropleth', locations=df$CODE, z=df$GDP..BILLIONS., text=df$COUNTRY, colorscale="Blues")
fig
shiny::runApp('R/9.Developing data products/Gayu_first_app/quiz1')
library(shiny)
library(miniUI)
pickXY <- function() {
ui <- miniPage(
gadgetTitleBar("Select Points by Dragging your Mouse"),
miniContentPanel(
plotOutput("plot", height = "100%", brush = "brush")
)
)
server <- function(input, output, session) {
output$plot <- renderPlot({
plot(data_frame$X, data_frame$Y, main = "Plot of Y versus X",
xlab = "X", ylab = "Y")
})
observeEvent(input$done, {
stopApp(brushedPoints(data_frame, input$brush,
xvar = "X", yvar = "Y"))
})
}
runGadget(ui, server)
}
my_data <- data.frame(X = rnorm(100), Y = rnorm(100))
pickXY(my_data)
library(miniUI)
library(shiny)
library(miniUI)
install.packages("miniUI")
library(miniUI)
pickXY <- function() {
ui <- miniPage(
gadgetTitleBar("Select Points by Dragging your Mouse"),
miniContentPanel(
plotOutput("plot", height = "100%", brush = "brush")
)
)
server <- function(input, output, session) {
output$plot <- renderPlot({
plot(data_frame$X, data_frame$Y, main = "Plot of Y versus X",
xlab = "X", ylab = "Y")
})
observeEvent(input$done, {
stopApp(brushedPoints(data_frame, input$brush,
xvar = "X", yvar = "Y"))
})
}
runGadget(ui, server)
}
my_data <- data.frame(X = rnorm(100), Y = rnorm(100))
pickXY(my_data)
knitr::opts_chunk$set(echo = FALSE)
plot(x=mtcars$wt, y=mtcars$mpg, xlab="Weight of Cars", ylab="MIles per Galon")
shiny::runApp('R/9.Developing data products/Shiny_Web_App_Project')
